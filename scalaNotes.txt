* call-by-value VS call-by-name
  def function(byValue : Int, byName : => Int) = ...

  def = by name
    def x = square(22) => evaluated at each use
  val = by value
    val x = square(22) => evaluated only once


  - def - defines an immutable label for the right side content which is lazily evaluated - evaluate by name + evaluated every time it gets accessed
        def can be overriden by val in subclasses, but not the other way around!
  - val - defines an immutable label for the right side content which is eagerly/immediately evaluated - evaluated by value.
  - lazy lav - evaluated lazily + properly only once + if you get exception during evaluation then another access will try to reevaluate it
  - var - defines a mutable variable, initially set to the evaluated right side content.

* lexical scope
  { ... } = is an expression!
  definitions from outside the block are visible inside the block
  definitions inside the block shadows definitions from outside the block
  definitions inside the block are not visible outside the block

* Multiple parameter lists - shortcut for function that return a function - for currying
  def sum(f: Int => Int)(a: Int, b: Int): Int   ===   def sum(f: Int => Int): (Int, Int) => Int
  usage: sum (cube) (10, 20)

* Dynamic dispatch of methods is analogous to calls to higher-order function
    Open questions?
      - can we implement Objects in terms of higher-order functions?
      - can we implement higher-order functions in terms of objects?

* Class Hierarchy
  Any (methods: ==, !=, equals, hashCode, toString)
    - AnyVal = all value classes (primitive classes)
      -- Int
      -- Boolean
      -- Unit
    - AnyRef = alias (different name) for java.lang.Object
      -- ScalaObject
        -- other Scala classes
      -- other Java classes
  Nothing = inherits from every Any class, but also inherits from Null => there's no value of type Nothing
    1. To signal abnormal termination => function that throws exception or terminates the program
      type of expression "throw Exception" is Nothing
    2. As an element type of empty collections => Set[Nothing]
  Null = inherits from every AnyRef class => the type of the "null" value
    val s: String = null //OK
    val i: Int = null //Error: type mismatch (because Null is subtype of all AnyRef, and Int is AnyVal)

* Constructor with field definitions:
  class A(val i: Int) => is equivalent to class A(_i: Int) { val i = _i }
  Field definitions in classes are just special cases of methods and can override methods

* Changing getters/setters of properties:
  if you start with class A(var i: Int) and want to override mutators then you need to refactor into
  class A(private var _i: Int) {
    def i: Int = _i                     //getter
    def i_=(newI: Int) = _i = newI      //mutator
  }
  Client code don't change, because obj.property is a shortcut for obj.property() and method name property_= allows client to use obj.property = XXX

* Pure Object-Oriented Language (every value is an object, type of each value is a class)
  - primitive types = Int / Boolean => are objects and you can treat them like objects, but scala compiler represent them as int/boolean for efficiency reasons (optimization)
  - functions = function values are objects in Scala (A => B is shortcut for scala.Function1[A,B]) with apply() method
  - methods = are not objects, but if used in a place where function value is expected it's automatically converted to the function value

  object List {
    //List(1, 2) ==> expands to: List.apply(1, 2)
    def apply[T](x1: T, x2: T): List[T] = new Cons(x1, new Cons(x2, new Nil))
    def apply[T]() = new Nil
  }

* Generics - Type Bounds
  [S <: IntSet] = S is subtype of type IntSet (upper bound)
    def assertAllPositive[S <: IntSet](s: S): S = ...
  [S >: IntSet] = S is supertype of T (or T is a subtype of S) (lower bound)
  [S >: NonEmpty <: IntSet] = mixing

* Generics - Covariance (Variance refers to how subtyping between more complex types (list of T, array of T) relates to subtyping between their components)
  Problem: Given: NonEmpty <: IntSet, does it makes sense to List[NonEmpty] <: List[IntSet] (A list of non-empty sets is a special case of a list of arbitrary sets)
  Covariant types hold this relationship
  in Java Arrays are covariant (Integer[] instanceof Number[] == true), but because of that array must keep the type of it's creation to check what type of elements are you putting in, to avoid problems with putting wrong types inside. It was necessary to implement Arrays.sort(Object[] a)

  Arrays are NOT Covariant in Scala (different than in Java) because Arrays are mutable !!!
  Lists are Covariant in Scala because Lists are immutable !!!

* Variance
  Given: A <: B
  Then: if C[A] <: C[B]  => C is covariant        => in Scala: class C[+A] { ... }
        if C[A] >: C[B]  => C is contravariant                 class C[-A] { ... }
        if none of above => C is nonvariant/invariant          class C[A]  { ... }

  Example: type A = IntSet => NonEmpty            => A <: B   (type A satisfies the same contract as type B, but it will satisfy even more)
           type B = NonEmpty => IntSet

  Rule for function types: If A2 <: A1 and B1 <: B2, then A1=>B1 <: A2=>B2
  Functions are contravariant in their argumet types and covariant in their result type.
    trait Function1[-T, +U] { def apply(x: T): U }
  Scala compiler check classes with variances for (simplified):
    - covariant type parameters can only appear in method results
    - contravariant type parameters can only apper in method parameters
    - invariant/nonvariant type parameters can appear anywhere

* Compiler can infer types => so if for example we put function parameter last, then probably compiler will infer types from the previous parameters, so we'd not need to write parameters of the give function

* Decomposition => ex. evaluation of expressions represented as a tree of objects of different classes
  1. x.isInstanceOf[T] && x.asInstanceOf[T]
  2. object-oriented decomposition => each class has it's own eval() method
    => what if we want to add additional method show()? We need to add it to all classes
    => operations that are not local to any single class => eg. simplification of expression (a*b + a*c == a*(b+c))? limitation of OO approach!
  3. Pattern Matching => using case classes
    => Observation: the purpose of test and access methods used in low-level, unsafe solutions in to reverse the creation process (what subclass was used, what were the arguments)
    trait Expr
    case class Num(n: Int) extends Expr
    case class Sum(e1: Expr, e2: Expr) extends Expr

    def eval(e: Expr) = e match {   // throws MatchError exception if no pattern matches
      case Num(n) => n              // matches also to subtypes of Num
      case Sum(e1, e2) => eval(e1) + eval(e2)
      case Num(10) => 100           // order matters => chooses first pattern that matches
      case Prod(Sum(e1, e2), e3) => 300 // to allow proper "()" of operations
      case _ => 999
      case Num(_) => 998
      case "abc" => 997             // matches in the sense of ==
      case x: List[Any] => 996      // matcher something that is of type List[Any] => and also does type casting!!!
    }

    x => x match { case c1 => e1 } is equivalent to: { case c1 => e1 }
    (xs zip ys) map { case (x, y) => x * y }

    Example:
    def flatten(xs: List[Any]): List[Any] =
      xs match {
        case Nil => Nil
        case x :: xs => x match {
          case y: List[Any] => flatten(y) ++ flatten(xs)
          case _ => x :: flatten(xs)
        }
      }
    flatten(List(List(1, 1), 2, List(3, List(5, 8)))) == List(1, 1, 2, 3, 5, 8)

* Function call syntax:
  # Arity-0: you can ommit ()
    fun()  <==> fun
  # Infix notation: for methods with 1 argument => use only for special cases
    a + b  <==> a.+(b)
  # Postfix notation: for methods with no arguments => discouraged (because semicolons (;) are optionals and it can cause strange compiler errors)
    names toList    <==>   names.toList
  # single parameter (x) can be replaced with {x}




* Case classes
  case class Num(n: Int)
  1. Automatic companion object with apply function
  object Num { def apply(n: Int) = new Num(n) }   // Num(1)
  2. Allows Pattern Matching
  3. equals (comparison by values), toString
  4. copy(title = "new value") method with option to replace some fields


* List (List(1,2,3) || Nil || 1 :: 2 :: Nil)
  - operators ending in ":" associate to the right
    A :: B :: C     ==>   A :: (B :: C)
  - operators ending in ":" are also treated as method calls of the right-hand side
    1 :: 2 :: Nil   ==>   Nil.::(2).::(1)
  - xs ::: ys => concatenation; rewriten as ys.:::(xs)
  - xs ++ ys => concatenation of collections/iterables
  - xs updated (n, x) => new list with modified element at position n
  - xs indexOf x => finding element x
  - xs contains x => finding element x


* Tuple
  - type: (String, Int) => shortcut for type scala.Tuple2[T1, T2]
  - creation: val pair = ("abc", 123) => shortcut for function application scala.Tuple2("abc", 123)
  - accessor: pair._1, pair._2
  - pattern matching:
      case (first, second) => ...
      val (a, b) = pair

* Implicit Parameters - corespond to implicit objects choosen by type T only (name doesn't matter, also there can't be multiple candidates with same type => eg. can't have 2 implicit String parameters)
  def mergeSort[T](xs: List[T])(implicit org: Ordering[T]): List[T]
  object Ordering {
    trait IntOrdering extends Ordering[Int] {
      def compare(x: Int, y: Int) = java.lang.Integer.compare(x, y)
    }
    implicit object Int extends IntOrdering
  }
  then you can use: mergeSort(List(3,2,1)) without additional ordering parameter

  Compiler will search for implicit definiton:
    - parameter || val || object marked as implicit
      implicit object { ... }
      implicit val iv = ...
    - has type compatible with T
    - is visible at the point of the function call or is defined in a companion object associated with T
    - error if multiple options available

* Implicit conversions = one argument functions or one argument class constructor
    implicit def agentCodename(i: Int) = s"00$i"
    def hello(name: String) = s"Hello, $name"
    hello(7) //"Hello, 007"

    implicit class Agent(code: Int) { ... }

    Usage: method injection!!!! and typeclasses!!!!
      1.minutes with implicit conversion Int => { def minutes = ... }

* Typeclasses pattern = the idea is that you provide evidence (ProofThatWrapperCanFoo) that a class (Wrapper) satisfies an interface (CanFoo)
    trait CanFoo[A] { def foos(x: A): String }
    case class Wrapper(wrapped: String)
    object ProofThatWrapperCanFoo extends CanFoo[Wrapper] { def foos(x: Wrapper) = x.wrapped }

  - Wrapper don't have to implement CanFoo directly. Typeclasses splits definition of the class and the implementation of the interface
  - So third party can implement interface for your classes
  - But then if you want to use a thing that CanFoo you need 2 arguments:
    def foo[A](thing: A, evidence: CanFoo[A]) = evidence.foos(thing)
  - To make it simpler other languages (Haskell) solve this by having only one CanFoo[A] for a given A (evidence objects are like global variables), but in Scala you use implicits
    implicit object ProofThatWrapperCanFoo extends CanFoo[Wrapper] { def foos(x: Wrapper) = x.wrapped }
    def foo[A](thing: A)(implicit evidence: CanFoo[A]) = evidence.foos(thing)
    foo(Wrapper("hi")) //object ProofThatWrapperCanFoo is the only thing in scope of type CanFoo[Wrapper]
  - Special syntax in Scala:
    def foo[A:CanFoo](thing: A) = implicitly[CanFoo[A]].foos(thing)
  - Or
    trait CanFoo[A] { def foos(x: A): String }
    object CanFoo { def apply[A:CanFoo]: CanFoo[A] = implicitly }
    case class Wrapper(wrapped: String)
    implicit object WrapperCanFoo extends CanFoo[Wrapper] { def foos(x: Wrapper) = x.wrapped }
    def foo[A:CanFoo](thing: A) = CanFoo[A].foos(thing)
    foo(Wrapper("hi")) //foo calls CanFoo.apply()
  - Or/And using implict conversions:
    implicit class CanFooOps[A:CanFoo](thing: A) { def foo = CanFoo[A].foos(thing) }
    def foo[A:CanFoo](thing: A) = thing.foo //implicit conversion to CanFooOps => CanFooOps(thing).foo


  Def: A type class is a type system construct that supports ad hoc polymorphism. This is achieved by adding constraints to type variables in parametrically polymorphic types. Such a constraint typically involves a type class T and a type variable a, and means that a can only be instantiated to a type whose members support the overloaded operations associated with T.


* Collections (immutable !!):
  * List => Linked-List
  * Vector => very shallow trees; more balanced access patterns than lists
    to 32 elements => simple Array; bigger each element changes into pointer to another Array (2^10 elements), ...
    Access: O(log32(N))
    better for bulk operations on multiple elements (each 32 elements group is located in a single Array close in the memory)
    x +: xs => adds element to the beginning of the vector
    xs :+ x => adds element the the end of the vector
    Modification: O(log32(N)) => some new objects needs to be created to have immutable structure
  * Seq => sequence
  * Array and String => comes from Java; behaves like Seq and can be converted easily to Seq
  * Range => sequence of evenly spaced integers
    1 to 10 by 3 (1 to 10 inclusive with step 3)
    1 until 5 (1 to 4)
  * Set = unordered, no duplicate elements, contains = fundamental operation
  * Map = Iterable && Function at the same time
    val roman = Map("I" -> I, "V" -> 5, "X" -> 10)
    roman("I") //function call, exception if no element found
    roman get "I" //Optional as the result
    val mapTotalFunction = map withDefaultValue "<unknown>" => return given value if function application fail => translates map partial function into total function


* xs flatMap f = (xs map f).flatten
* For expression: no side effect; produces new results with yield expression
  persons: collection of case class Person
  for (p <- persons if p.age < 20) yield p.name   ==>   persons filter (p => p.age > 20) map (p => p.name)
  for ( s ) yield e
    where s = sequence of generators and filters divided by ";" or { s } with multiple lines without ";"
    for {
      i <- 1 until n
      j <- 1 until i
      if isPrime(i, j)
    } yield (i, j)

  If result is Nil, then of course map will return Nil and yield will be never called!!!
    val someValue = "abc"
    val result = for {
      listElement <- functionThatReturnNil
    } yield (someValue :: listElement)
    //result will be Nil, because yield will never be called

* Option => None || Some(x)
  trait Option[+A]
  case class Some[+A](value: A) extends Option[A]
  object None extends Option[Nothing]
* Varargs => Repeated Parameters with "*" after type: (bindings: (Int, Double)*)

* Lazy vs Strict Collections:
  - lazy can need less space, but lazy can be slower if you need to recompute values multiple times; needs purely functional architecture!!!! (be more smart at what you do with it)
  - strict can need more space for intermediate results, but it can be faster in some cases
  - scala colections are mostly strict eg. list filter ... => but you also have lazy semantics in some places eg. list withFilter ...
  - list.view => returns lazy collection!!!
  - lazy collections are hard in not pure-functional paradigm!!! With laziness you can start having additional problems:
    eg.
      val xs = List(1,2,0) //then it's strict and you catch exception and return Nil
      val xs = List(1,2,0).view //then it's lazy and you don't catch exception!!!! Map will return the view, and nothing will be computed!!!!
      val result = try xs.map(1 / _) catch { case ex: ArithmeticException -> Nil }
  - Collections Imperative (2 basic operations: iterator, add that modifies collection) VS Functional (immutable, transformations that transform collection to different collection)

* String features
  - String interpolation:
    val name = "John Do"
    val ret = s"Hello, $name"








Nauka programowania:
  * https://lightbot.com

Additional things:
  * https://www.scala-exercises.org => przykaÅ‚ady do nauki Scala

Combinator = function that is dependant only on it's input parameters (no free variables)

Diassembling Scala code:
  * javap -p => shows public and private members of the class
  * javap -c => shows implementation of the methods



????? For Future ?????
* How to integrate easily parts of application in Scala into existing Java maven/... project => http://davidb.github.io/scala-maven-plugin/example_java.html
* Parallel Collections
* Distributed Collections
* Actors = Akka
* DSLs = scala parser combinators library build into scala => to create internal DSLs easily
  http://bitwalker.org/posts/2013-08-10-learn-by-example-scala-parser-combinators/
  https://github.com/scala/scala-parser-combinators/blob/1.0.x/docs/Getting_Started.md
  http://debasishg.blogspot.com/2008/04/external-dsls-made-easy-with-scala.html
* "Scala in Depth" book => ex. Loaner Pattern
* ScalaZ = pure functional
* https://github.com/bigdatagenomics => genomics analysis framework open-source








..:: Spark ::..
* Architecture:
  Spark FileSystem (HDFS, Cassandra) <---> Spark Runtime <---> ClusterManager (Yarn, Mesos)
  Spark with Scala: User input <---> Scala REPL <---> Spark Runtime <---> Scala Runtime <---> JVM

* DSLs - reasons to use
  1. Support new syntax => just sytanx, usually shallow
  2. Support new functionality (new dimention) => like Spark => move computation from a single computer to a whole cluster => non-standard compiler pipeline or execution pipeline

* Spark = DSL centered around Collections => immutable data sets equipped with functional transformers
  RDD = Resilient Distributed Datasets
  Scala collections, but running on cluster, with fundamental differences:
    - Spark is lazy (Scala collections are strict)
    - Spark has added functionality (eg. PairRDDs) (eg. cache() operation that takes and persists snapshot of current data to not have to recompute it again)
